# -*- coding: utf-8 -*-
"""exam01_Introduction_to_machine_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17B-xXk0BPatFocDW_ue-Jt7FcwEJVLX7

# 머신러닝(딥러닝)입문
"""



"""#Linear regression

"""



"""#기존의 프로그램 방식"""

def celsius_to_fahrenheit(x):
  return x * 1.8 + 32

celsius_value = int(input('섭씨온도를 입력하시오.'))
print('화씨온도로', celsius_to_fahrenheit(celsius_value))

"""### 머신러닝 방식"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, InputLayer
import numpy as np
import matplotlib.pyplot as plt

data_C= np.array(range(0,100))
data_F=celsius_to_fahrenheit(data_C)
print(data_C)
print(data_F)

model = Sequential()
model.add(InputLayer(input_shape=(1,)))
model.add(Dense(1))
model.compile(loss='mse',optimizer='rmsprop')
model.summary()

scaled_data_C =data_C/100 # 이유: 발산을 막기 위해서, learning rate를 곱하기도 전에 너무 커져서 발산할까봐 비례적으로 줄이는 거야. 그래서 scale이 0에서 100정도 되니까 100으로 나눈거야.
scaled_data_F = data_F/100
print(scaled_data_C)
print(scaled_data_F)

print(model.predict([0.01]))

model.save('before_learning.h5')

fit_hist=model.fit(scaled_data_C,scaled_data_F, epochs =1000) # 1000번 학습 시킴.

print(model.predict([0.01]))

model.save('after_learing.h5')

plt.plot(fit_hist.history['loss'])
plt.show()

noise = np.array(np.random.normal(0,0.05,100))
print(noise)

noised_scaled_data_F = np.array([])
for data in scaled_data_F:
  noised_scaled_data_F = np.append(
  noised_scaled_data_F, np.random.normal(0,0.05,100)+data)
  print(noised_scaled_data_F)
  print(len(noised_scaled_data_F))

import numpy as np

noised_scaled_data_C = []

for data in range(0, 100):
    for i in range(0, 100):
        noised_scaled_data_C.append(data)

noised_scaled_data_C = np.array(noised_scaled_data_C)
noised_scaled_data_C = noised_scaled_data_C / 100

print(noised_scaled_data_C)
print(len(noised_scaled_data_C))

plt.scatter(x=noised_scaled_data_C, y=noised_scaled_data_F)
plt.show()

fig=plt.figure(figsize=(50,50))
ax = fig.add_subplot(111)
ax.scatter(x=noised_scaled_data_C, y=noised_scaled_data_F,alpha=0.02,s=200,marker='+')
plt.show()

model2 = Sequential()
model2.add(InputLayer(input_shape=(1,)))
model2.add(Dense(1))
model2.compile(loss='mse',optimizer='rmsprop')
model2.summary()

model2.predict([0.01]) # 회귀 모델의 예측 수행, 정답을 예측하기 위함. 오차가 가장 적게 해서
# 입력 값 0.01에 대한 예측을 얻기 위해 model2.predict 함수를 사용함

fit_hist=model2.fit(scaled_data_C,scaled_data_F, epochs =20)

model2.save('noised_after_learning.h5')

print(model2.predict([0.01]))

celsius_value = int(input('섭씨 온도를 입력하세요'))
print('화씨 온도로', model2.predict([celsius_value / 100])*100)

celsius_value = int(input('섭씨 온도를 입력하세요'))
print('화씨 온도로', model2.predict([celsius_value / 100])*100)

celsius_value = int(input('섭씨 온도를 입력하세요.'))
print('화씨 온도로',np.around(model2.predict([celsius_value / 100])*100, 1),'입니다.')

plt.plot(fit_hist.history['loss'])
plt.show()

