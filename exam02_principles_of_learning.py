# -*- coding: utf-8 -*-
"""exam02_principles_of_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15K7PFCfj3fp45TJvmEXs5jviXCezLWHo

# 그래프 연산
"""

class add_graph:
  def __init__(self): #  - `__init__` 메서드는 클래스의 생성자로, 객체가 생성될 때 한 번 호출됩니다. 여기에서 `self`는 생성되는 인스턴스를 가리킵니다.
    pass  # pass를 사용함으로써 코드는 문법적으로 올바르게 유지되면서 아무런 동작도 수행하지 않습니다.
  def forward(self,x,y): # forward` 메서드는 두 개의 숫자를 더하는 작업을 수행합니다. 여기에서 `self`는 해당 인스턴스를 가리키며, `x`와 `y`는 메서드에 전달된 매개변수입니다.
    out = x+y
    return out
  def backward(self,dout): # backward` 메서드는 미분 값에 대한 역전파를 수행합니다. `dout`은 미분 값
    dx = 1 * dout
    dy = 1 * dout
    return dx, dy

class mul_graph:
  def __init__(self):
    self.x =None # self.x 값 null 이라도 정의
    self.y=None
  def forward(self,x,y):
    self.x=x # self 에 있는 x
    self.y=y
    out = x*y
    return out
  def backward(self, dout): # 체인룰
    dx = self.y * dout # x에 대한 미분값
    dy = self.x * dout # y에 대한 미분값
    return dx,dy

class mse_graph:
  def __init__(self):
    self.loss = None # null
    self.y= None
    self.t =None
    self.x = None
  def forward(self, y, t):
    self.t = t # 실제 정답(ground truth) 데이터
    self.y = y #모델의 예측값
    self.loss = np.square(self.t-self.y).sum()/ self.t.shape[0] # sum 배열의 모든 원소를 더함, / self.t.shape[0]: 데이터 포인트의 개수로 나누어 평균을 계산
    # 평균 제곱 오차(Mean Squared Error, MSE)를 계산하는 부분입니다. MSE는 회귀 문제에서 모델의 예측값과 실제 값 간의 차이를 제곱한 것들의 평균을 나타내는 지표
    return self.loss # 모델의 현재 예측이 실제 값과 얼마나 차이나는지를 나타내는 평균 제곱 오차가 저장

  def backward(self, x , dout=1):
    data_size = self.t.shape[0]
    dweight_mse = (((self.y - self.t)*x).sum()*2/data_size) # 평균 제곱 오차(Mean Squared Error, MSE) 손실 함수에 대한 가중치(weight)에 대한 편미분값을 계산
    dbias_mse = (self.y-self.t).sum()*2 / data_size
    return  dweight_mse, dbias_mse

apple = 100
apple_num= 2
orange = 150
orange_num = 3
tax =1.1

mul_apple_graph = mul_graph() # 곱셈
mul_orange_graph = mul_graph() # 곱셈
add_apple_orange_graph = add_graph() # 덧셈
mul_tax_graph = mul_graph() # 곱셈

apple_price=mul_apple_graph.forward(apple, apple_num) # 사과 가격, 사과 갯수 - 총 사과 가격
orange_price = mul_orange_graph.forward(orange, orange_num)  # 오렌지 가격, 오렌지 갯수 -  총 오렌지 가격
all_price = add_apple_orange_graph.forward(apple_price, orange_price) # 총 사과가격 + 오렌지 가격
total_price = mul_tax_graph.forward(all_price, tax) # all price 미분값
print(total_price)# total 가격

1.1+0.1 == 1.2  # float 값은 일부의 오차가 존재하기 때문에 false 가 나와( 이진화 에러로 인해서 )

1+1 ==2

dprice = 1
dall_price, dtax = mul_tax_graph.backward(dprice)
dapple_price, dorange_price = add_apple_orange_graph.backward(dall_price)
dorange, dorange_num = mul_orange_graph.backward(dorange_price)
dapple, dapple_num = mul_apple_graph.backward(dapple_price)

print('dApple', dapple)
print('dApple_num', dapple_num)
print('dOrange',dorange)
print('dOrange_num',dorange_num)

import numpy as np

def celcius_to_fahrenheit(x):
  return x+1.8+32

weight = np.random.uniform(0, 5, 1)
print(weight)
bias = 0

data_C = np.arange(0, 100)
data_F = celcius_to_fahrenheit(data_C)
scaled_data_C = data_C/ 100
scaled_data_F = data_F / 100
print(scaled_data_C)
print(scaled_data_F)

weight_graph = mul_graph()
bias_graph = add_graph()

weighted_data = weight_graph.forward(weight, scaled_data_C)
predict_data = bias_graph.forward(weighted_data, bias)
print(predict_data) # 틀린 값 100가 만들어짐.

dout = 1
dbias, dweighted_data = bias_graph. backward(dout)
dweight, dscaled_data_C = weight_graph.backward(dweighted_data)
print(dbias) # bias의 미분값은 1
print(dweight) # dweight의 미분값은 100개가 나옴.  # mse 에러 값을 낼때 평균낸다는 의미

mseGraph = mse_graph()
mse = mseGraph.forward(predict_data, scaled_data_F)
print(mse)

weight_mse_gradient, bias_mse_gradient = mseGraph.backward(scaled_data_C)
print(weight_mse_gradient)
print(bias_mse_gradient)

learning_rate=0.1
learned_weight=weight- \
  learning_rate * weight_mse_gradient * np.average(dweight)
print('before learning weight:',weight)
print('after learning weight:',learned_weight)

learned_bias = bias - learning_rate *bias_mse_gradient * dbias
print('before learning bias:',bias)
print('after learning bias:',learned_bias)

error_list = []
weight_list = []
bias_list = []
for i in range(1000):
  #forward
  weighted_data = weight_graph.forward(weight, scaled_data_C)
  predict_data = bias_graph.forward(weighted_data, bias)
  # backward
  dout = 1
  dbias, dweighted_data = bias_graph.backward(dout)
  dweight, dscaled_data_C =  weight_graph.backward(dweighted_data)
  #mse
  mse = mseGraph.forward(predict_data, scaled_data_F)
  error_list.append(mse)
  weight_mse_gradient, bias_mse_gradient = \
    mseGraph.backward(scaled_data_C)
  #learning
  weight_list.append(weight)
  weight = weight - learning_rate * weight_mse_gradient * np.average(dweight)
  # 경사 하강법을 사용하여 가중치 업데이트
# weight: 현재의 가중치
# learning_rate: 학습률, 가중치 업데이트의 크기를 결정
# weight_mse_gradient: 평균 제곱 오차(Mean Squared Error)에 대한 가중치의 기울기
# np.average(dweight): 가중치에 대한 평균 기울기(각 샘플에 대한 기울기의 평균)

  bias_list.append(bias)
  bias = bias - learning_rate * bias_mse_gradient * dbias
weight_list.append(weight)
bias_list.append(bias)
print(weight)
print(bias)

print(error_list[-1])

import matplotlib.pyplot as plt
plt.plot(error_list)
plt.show()

plt.plot(weight_list)
plt.show()

plt.plot(bias_list)
plt.show()

